# GenAI-SLM

Small Language Models

Improved Privacy, Domain Specific and Lower Computational Requirements This session will demonstrate a prototype "Device Helper" assistant that helps users quickly find features and navigate the menus on a mobile device. We will explore the GraphRAG based implementation built using Small Language Models (SLMs) such as BERT and Gemma2b, running on a CPU-based system. Despite their inherent limitations, SLMs like Gemma2b offer a less costly alternative to Large Language Models (LLMs) with reduced infrastructure needs, and enhanced data privacy. We will also delve into challenges encountered, such as finding a suitable dataset and the limitations of vector stores (resolved by fine-tuning BERT).
